{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars: Homework on Scraping and Web Analysis: Alternative Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Scrape https://mars.nasa.gov/news/ and collect News Titles and Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies. Will use pandas for processing, BeautifulSoup to grab data, requests to pull html text, and MongoDB\n",
    "#and Splinter for repository data storage.\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping started\n"
     ]
    }
   ],
   "source": [
    "print(\"scraping started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mars News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL for collecting html data on Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://mars.nasa.gov/news\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser.visit to view URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach: Grab data from 'li' tags as a list, then iterate to extract title, paragraph text, and reference for making a list of dictionaries suitable for MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative try to grab <li> tags, which have all of the articles.\n",
    "#Then use iteration for loop to extract the title, teaser paragraph, and reference.\n",
    "#Empty list for appending dictionaries of data for articles.\n",
    "top_data = []\n",
    "\n",
    "#Iteration knowing 40 articles per page and target of 400 articles\n",
    "#for x in range(1,11):\n",
    "    \n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "init_data = soup.find_all('li', class_='slide')\n",
    "\n",
    "#Construct a list of dictionaries with these data for incorporation into MongoDB. Include\n",
    "#'mars.nasa.gov' to enable direct use of the reference as a URL.\n",
    "for item in init_data:\n",
    "    title = item.find('div', class_='content_title').text\n",
    "    teaser = item.find('div', class_='rollover_description_inner').text\n",
    "    ref = 'mars.nasa.gov' + item.a['href']\n",
    "    \n",
    "    dictionary = {\n",
    "        'title': title,\n",
    "        'teaser': teaser,\n",
    "        'reference': ref  \n",
    "    }\n",
    "    \n",
    "    top_data.append(dictionary)\n",
    "\n",
    "#Following code from https://stackoverflow.com/questions/29773368/splinter-how-to-click-a-link-button-implemented-as-a-div-or-span-element\n",
    "#button = browser.find_by_name('More')\n",
    "#button.click()\n",
    "#browser.click_link_by_text('More')\n",
    "#browser.click_link_by_partial_text('More')\n",
    "\n",
    "#Link address for \"More\" button   \n",
    "#https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest#    \n",
    "\n",
    "#This range/browser.click_link for 'More' didn't seem to work. I was able to manually\n",
    "#click the More link and obtain a lot more articles. There should be a way to adapt\n",
    "#the click_link_by_partial_text('More') to obtain a given number of articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check top_data list of dictionaries to confirm formatting and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_data[39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. JPL Mars Space Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Url for Mars Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visit url with browser, then create BeautifulSoup object to grab image information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_2 = browser.html\n",
    "soup_2 = bs(html_2, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image_data = soup_2.find_all('article', class_=\"carousel_item\")\n",
    "#raw_image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw_image_data is a list, so take element [0] to extract string data on the 'style' tag. Extract the reference url for the full-size image and add the full information for generating the complete url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little tricky because only one element in list. j element ([0]) and isolate\n",
    "# the 'style' tag. The url is not a tag, so can't use it to isolate the url information.\n",
    "for j in raw_image_data:\n",
    "    raw_url = j['style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_image_url = 'jpl.nasa.gov' + raw_url.split(\"'\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary for featured image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_image_dict = {\n",
    "    'featured image url': featured_image_url\n",
    "}\n",
    "#featured_image_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mars Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The url for Mars weather via twitter.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3 = 'https://twitter.com/marswxreport?lang=en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup browser.html and create BeautifulSoup object for parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_3 = browser.html\n",
    "soup_3 = bs(html_3, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In other cases, used find_all to get all instances. I think this time we want the most recent weather data, so used .find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather_raw = soup_3.find('div', class_=\"js-tweet-text-container\")\n",
    "#mars_weather_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract current Mars weather from the twitter url current data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_mars_weather = mars_weather_raw.p.text.replace('\\n', ', ').split('pic')[0]\n",
    "#current_mars_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary for these weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather_dict = {\n",
    "    'current mars weather': current_mars_weather\n",
    "}\n",
    "#mars_weather_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Mars Facts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New url for Mars Facts Website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_4 = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pandas to extract table information and reference for inclusion in website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(url_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables[0] and [1] have relevant data for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_data = tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_comparison_data = tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and set index to Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_mars_data = mars_data.rename(columns = {0: 'Parameters', 1: 'Measurements'})\n",
    "#renamed_mars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mars_comparison_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataframes as html formatted tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_mars_data.to_html('Mars_Data_Table.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_comparison_data.to_html('Mars_Earth_Comparison_Data.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of dictionaries for mars data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_data = [\n",
    "    {\n",
    "    'data table 1': 'Mars_Data_table.html'\n",
    "    },\n",
    "    {\n",
    "    'data table 2': 'Mars_Earth_Comparison_Data.html'   \n",
    "    }\n",
    "]\n",
    "#mars_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Mars Hemispheres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLs for high resolution images of Martian hemispheres. Attepmted to find a single webpage with all of these links, but did not find one. Will have to scrape each individual webpage, one for each Martian hemisphere. Main URL for website below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_5 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerberus Hemisphere Enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5a = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_5a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_5a = browser.html\n",
    "soup_5a = bs(html_5a, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerberus_raw = soup_5a.find_all('img', class_=\"wide-image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in cerberus_raw:\n",
    "    cerberus_url = 'astrogeology.usgs.gov' + data['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cerberus_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schiaparelli Hemisphere Enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5b = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_5b = browser.html\n",
    "soup_5b = bs(html_5b, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiaparelli_raw = soup_5b.find_all('img', class_=\"wide-image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in schiaparelli_raw:\n",
    "    schiaparelli_url = 'astrogeology.usgs.gov' + data['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schiaparelli_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syrtis Major Hemisphere Enhanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5c = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_5c = browser.html\n",
    "soup_5c = bs(html_5c, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "syrtis_major_raw = soup_5c.find_all('img', class_=\"wide-image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in syrtis_major_raw:\n",
    "    syrtis_major_url = 'astrogeology.usgs.gov' + data['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syrtis_major_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valles Marineris Hemisphere Enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5d = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url_5d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_5d = browser.html\n",
    "soup_5d = bs(html_5d, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "valles_marineris_raw = soup_5d.find_all('img', class_=\"wide-image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in valles_marineris_raw:\n",
    "    valles_marineris_url = 'astrogeology.usgs.gov' + data['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valles_marineris_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct image titles and url's list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Cerberus Hemisphere Enhanced', 'Schiaparelli Hemisphere Enhanced', 'Syrtis Major Hemisphere Enhanced', 'Valles Marineris Hemisphere Enhanced']\n",
    "urls = [cerberus_url, schiaparelli_url, syrtis_major_url, valles_marineris_url]\n",
    "\n",
    "image_urls= []\n",
    "\n",
    "for x in range(len(titles)):\n",
    "    dictionary = {\n",
    "    'hemisphere': titles[x], 'img-url': urls[x]    \n",
    "    }\n",
    "    \n",
    "    image_urls.append(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Combine all Dictionaries and Lists of Dictionaries into a single list of dictionaries: total_mars_data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First construct a list to total_mars_data, then iterate through all other lists and dictionaries and append."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mars_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_data is a list of dictionaries with recent articles. Iterate through list and append dictionaries to total_mars_data list.\n",
    "for d in top_data:\n",
    "    total_mars_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next append featured_image_url dictionary\n",
    "total_mars_data.append(featured_image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next append mars_weather_dict\n",
    "total_mars_data.append(mars_weather_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next append mars data table information by iteration as in top_data.\n",
    "for m in mars_data:\n",
    "    total_mars_data.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same approach as for top_data list.\n",
    "for u in image_urls:\n",
    "    total_mars_data.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_mars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_mars_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Transfer the total_mars_data into a Mongo Database called Mars_DataDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize pymongo connection to mongod on local machine port localhost:27017(make certain mongod is running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define database (Mars_DataDB) and collection (db.scraped_mars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.Mars_DataDB\n",
    "collection = db.scraped_mars_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the data in collection before appending new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through total_mars_data and insert each dictionary into the scraped_mars_data collection. Note that a try/except error catching may be needed if some of the scraping data is not formatted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try: (remember that for loop will need to be indented if try is used)\n",
    "for data in total_mars_data:\n",
    "    collection.insert_one(data)\n",
    "    \n",
    "#except (remember to enter the exception if try fails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checked MongoDB and confirmed Mars_DataDB and the scraped_mars_data collection were created and active. All data was inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping finished\n"
     ]
    }
   ],
   "source": [
    "print(\"scraping finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
